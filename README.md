# BootCamp_Project

- Analyze a dataset consisting of 6,000 Youtube Videos to discover the pattern of list of trending videos. Once analysis is done, use machine learning model to predict the features/variables are primary key criteria resulting the videos to make it trending. 

## Dataset
Number of dataset reviewed before finalizing the Youtube Video Dataset from sopurce - Kaggle.com
- Youtube trending Video 
- Travel insurance 
- Reading Habits
- Retail data set - Walmart
- House Sales 
- Vehicle fuel type

## For the selected dataset, below are the questions we are hoping to answer using predictive model.

## Youtube trending Video
- Perform analysis of trending videos by each feature (category, Tags, Likes, comments,title etc.). Use Machine learning models to predict What features could make a video trending on YouTube. 
- Using USA country dataset

## Topic Selection and Reason for the selection

A) General Reason
1. A useful topic for Youtube content creators. 
2. Youtube is a global platform with over 2 billion users
3. The analysis will be usefule for promotional and marketing purpose.
4. Youtubers/Business/Professionals can use this model as an input before uploading their videos to make their videos popular/ trending.


B) Project specific reason
1. Availability of the dataset
2. Availability of number of records for the data required to perform the analysis.
3. Applicability of tools and technologies learnt during the course to meet the deliverables.

## Description of source of the data
This dataset is available on Kaggle where the publisher has extracted it from the Youtube API.This dataset is a daily record of the top trending YouTube videos available in a CSV format. It contains details such as video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count. The Category_id which represents video category is available in an associated JSON file. Source:  https://www.kaggle.com/datasnaek/youtube-new?select=USvideos.csv

## Team member roles 
- Square - Dixie Peralta
- Triangle - Neeraja Jayaraman & Nisha Bharakhada
- Circle - Dixie Peralta & Richelle Long
- X - Dixie Peralta, Richelle Long, Neeraja Jayaraman & Nisha Bharakhada

## Commmunication protocol
1. Git Hub - Coding, ReadMe, Commits and Final Project Results  
2. Slack - Team's main communication  
3. Google Drive  - For Assignments, Documents and Notes  
4. Zoom - Daily / Weekly meetups

## Presentation
- Provisional Machine learning Model - Neeraja and Nisha
- Provisional Database - Dixie & Richelle

## Communication protocols Include PNGs for these spreadsheets.

## Tools used to understand/review the dataset to meet the Project Deliverables.

- Microsoft Excel - To view the data once csv file is downloaded
- Postgress SQL - To create a database
- Python (Jupyter Notebook)
- QBD - To create ERD diagram
- Github
- Google Drive - To keep all the documents at one central location


## Machine Learning Model Description

- Multiple Regression Model 

## Database Description
PostgreSQL â€“ Relational Database System
![DB_ERD_SQL_posGres.png] (/ETL/DB_ERD_SQL_posGres.png)


Quick Database Diagrams
![ETL/ERD.png](/ETL/ERD.png)

# Technologies Used
## Data Cleaning and Analysis
- Pandas/Numpy/ Datetime will be used to clean the data and perform an exploratory analysis. Further analysis will be completed using Python.
## Database Storage
- Postgres Sql is the database we intend to use.
## Machine Learning
- SciKitLearn is the ML library we'll be using to create a classifier. Our training and testing setup is ___. 


